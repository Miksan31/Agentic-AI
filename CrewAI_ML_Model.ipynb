{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Q99OHvRnWv5zZmvGbNp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miksan31/Agentic-AI/blob/main/CrewAI_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn crewai crewai_tools --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DKIp9Evcp84",
        "outputId": "8e940129-1b48-4d77-ee11-17a2ab784769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.0/134.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.3/91.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m259.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.2 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_R8kO1Scecp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from crewai import Agent, Crew, Task, Process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the dataset\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded file\n",
        "dataset_file = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded dataset: {dataset_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "a79Lg74odNO0",
        "outputId": "91032136-9489-40e1-c31b-ab1240b497f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad727073-9b08-497d-8fe2-986bbd8040e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad727073-9b08-497d-8fe2-986bbd8040e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Salary_dataset.csv to Salary_dataset.csv\n",
            "Uploaded dataset: Salary_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.agent import Agent\n",
        "\n",
        "# Define the preprocessing agent\n",
        "preprocess_agent = Agent(\n",
        "    role=\"Data Preprocessor\",\n",
        "    goal=\"Prepare the data for machine learning by cleaning and splitting it into train and test sets.\",\n",
        "    backstory=\"I clean, organize, and split data to make it ready for training and evaluation.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Define the training agent\n",
        "train_agent = Agent(\n",
        "    role=\"Model Trainer\",\n",
        "    goal=\"Train a machine learning model (Linear Regression) using the training dataset.\",\n",
        "    backstory=\"I build predictive models based on data to solve problems.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "# Define the evaluation agent\n",
        "eval_agent = Agent(\n",
        "    role=\"Model Evaluator\",\n",
        "    goal=\"Evaluate the trained model using the test dataset.\",\n",
        "    backstory=\"I measure and analyze how well the model performs.\",\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "dmIWNY1MmjNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Task for Preprocessing\n",
        "preprocess_task = Task(\n",
        "    description=\"Clean and preprocess the dataset. Remove missing values, split the dataset into features (X) and target (y), and then split into training and testing sets.\",\n",
        "    expected_output=\"Preprocessed data including X_train, X_test, y_train, and y_test ready for training.\",\n",
        "    agent=preprocess_agent,\n",
        ")\n",
        "\n",
        "# Define Task for Training\n",
        "train_task = Task(\n",
        "    description=\"Train a Linear Regression model using the preprocessed training dataset.\",\n",
        "    expected_output=\"A trained Linear Regression model ready for evaluation.\",\n",
        "    agent=train_agent,\n",
        ")\n",
        "\n",
        "# Define Task for Evaluation\n",
        "eval_task = Task(\n",
        "    description=\"Evaluate the trained model on the test dataset and calculate performance metrics (Mean Squared Error, R-squared).\",\n",
        "    expected_output=\"Model evaluation metrics including Mean Squared Error (MSE) and R-squared value.\",\n",
        "    agent=eval_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "j0tFzV_0m4KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Task, Agent\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Define the Agents\n",
        "preprocess_agent = Agent(\n",
        "    role=\"Data Preprocessor\",\n",
        "    goal=\"Prepare the dataset by cleaning, organizing, and splitting into train/test sets.\",\n",
        "    backstory=\"I prepare raw data to ensure it's ready for analysis.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "train_agent = Agent(\n",
        "    role=\"Model Trainer\",\n",
        "    goal=\"Train a regression model on the provided dataset.\",\n",
        "    backstory=\"I build predictive models from data for actionable insights.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "eval_agent = Agent(\n",
        "    role=\"Model Evaluator\",\n",
        "    goal=\"Evaluate the trained regression model.\",\n",
        "    backstory=\"I measure model performance using key metrics.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Define Task for Preprocessing\n",
        "preprocess_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Data Preprocessing Task\n",
        "\n",
        "    1. Load the dataset from the provided file.\n",
        "    2. Clean the data by removing any rows with missing values.\n",
        "    3. Split the dataset into features (X) and target (y).\n",
        "    4. Split the data into training and testing sets (80% for training, 20% for testing).\n",
        "\n",
        "    ```python\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(dataset_file)\n",
        "\n",
        "    # Clean data by dropping rows with missing values\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Split dataset into features (X) and target (y)\n",
        "    X = df.drop('target_column', axis=1)  # Replace 'target_column' with actual target column name\n",
        "    y = df['target_column']  # Replace with actual target column name\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    ```\n",
        "\n",
        "    The output should be the preprocessed data (X_train, X_test, y_train, y_test).\n",
        "    \"\"\",\n",
        "    expected_output=\"Preprocessed data including X_train, X_test, y_train, and y_test.\",\n",
        "    agent=preprocess_agent,\n",
        ")\n",
        "\n",
        "# Define Task for Training the Model\n",
        "train_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Model Training Task\n",
        "\n",
        "    1. Train a Linear Regression model using the preprocessed data (X_train, y_train).\n",
        "    2. The model should be trained using the Linear Regression algorithm from sklearn.\n",
        "\n",
        "    ```python\n",
        "    # Train a Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Output the trained model\n",
        "    trained_model = model\n",
        "    ```\n",
        "\n",
        "    The output should be a trained Linear Regression model.\n",
        "    \"\"\",\n",
        "    expected_output=\"A trained Linear Regression model.\",\n",
        "    agent=train_agent,\n",
        ")\n",
        "\n",
        "# Define Task for Evaluating the Model\n",
        "eval_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Model Evaluation Task\n",
        "\n",
        "    1. Evaluate the trained model using the test data (X_test, y_test).\n",
        "    2. Calculate and return the Mean Squared Error (MSE) and R-squared value.\n",
        "\n",
        "    ```python\n",
        "    # Evaluate the trained model\n",
        "    y_pred = trained_model.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Calculate R-squared value\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Output the evaluation metrics\n",
        "    evaluation_metrics = {'MSE': mse, 'R-squared': r2}\n",
        "    ```\n",
        "\n",
        "    The output should be the model evaluation metrics (MSE and R-squared).\n",
        "    \"\"\",\n",
        "    expected_output=\"Model evaluation metrics including Mean Squared Error (MSE) and R-squared value.\",\n",
        "    agent=eval_agent,\n",
        ")\n",
        "\n",
        "# Define the workflow and provide configuration explicitly\n",
        "def main():\n",
        "    crew = Crew(\n",
        "        agents=[preprocess_agent, train_agent, eval_agent],\n",
        "        tasks=[preprocess_task, train_task, eval_task],\n",
        "        verbose=True,  # Enable logging during execution\n",
        "        config={}  # Explicitly pass an empty config if needed\n",
        "    )\n",
        "\n",
        "    # Define inputs (dataset file path)\n",
        "    inputs = {\n",
        "        \"dataset_file\": \"Salary_dataset.csv\",  # Replace with your dataset filename\n",
        "    }\n",
        "\n",
        "    # Execute the workflow\n",
        "    result = crew.kickoff(inputs=inputs)\n",
        "\n",
        "    print(\"\\n\\n########################\")\n",
        "    print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Step 5: Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    result = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gJxrWDSMnA1t",
        "outputId": "13e719e1-8872-4d77-cf6b-8fa51fdf3732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Missing required template variable ''MSE'' in description",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36minterpolate_inputs_and_add_conversation_history\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"'MSE'\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-52c28611d867>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Step 5: Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-52c28611d867>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Execute the workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n########################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_tasks_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interpolate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;34m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         [\n\u001b[0m\u001b[1;32m   1096\u001b[0m             task.interpolate_inputs_and_add_conversation_history(\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# type: ignore # \"interpolate_inputs\" of \"Task\" does not return a value (it only ever returns None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;34m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         [\n\u001b[0;32m-> 1096\u001b[0;31m             task.interpolate_inputs_and_add_conversation_history(\n\u001b[0m\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# type: ignore # \"interpolate_inputs\" of \"Task\" does not return a value (it only ever returns None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36minterpolate_inputs_and_add_conversation_history\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;34mf\"Missing required template variable '{e.args[0]}' in description\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             ) from e\n",
            "\u001b[0;31mValueError\u001b[0m: Missing required template variable ''MSE'' in description"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-7AXPDgWjtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpC9S2FXWjgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUtN6fbDWjQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Task, Process, Agent\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Define the Agents\n",
        "preprocess_agent = Agent(\n",
        "    role=\"Data Preprocessor\",\n",
        "    goal=\"Prepare the dataset by cleaning, organizing, and splitting into train/test sets.\",\n",
        "    backstory=\"I prepare raw data to ensure it's ready for analysis.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "train_agent = Agent(\n",
        "    role=\"Model Trainer\",\n",
        "    goal=\"Train a regression model on the provided dataset.\",\n",
        "    backstory=\"I build predictive models from data for actionable insights.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "eval_agent = Agent(\n",
        "    role=\"Model Evaluator\",\n",
        "    goal=\"Evaluate the trained regression model.\",\n",
        "    backstory=\"I measure model performance using key metrics.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Define Task for Preprocessing\n",
        "preprocess_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Data Preprocessing Task\n",
        "\n",
        "    1. Load the dataset from the provided file.\n",
        "    2. Clean the data by removing any rows with missing values.\n",
        "    3. Split the dataset into features (X) and target (y).\n",
        "    4. Split the data into training and testing sets (80% for training, 20% for testing).\n",
        "    \"\"\",\n",
        "    expected_output=\"Preprocessed data including X_train, X_test, y_train, and y_test.\",\n",
        "    agent=preprocess_agent,\n",
        "    output=[\"X_train\", \"X_test\", \"y_train\", \"y_test\"],\n",
        "    action=lambda inputs: {\n",
        "        # Load and preprocess the dataset\n",
        "        \"X_train\": train_test_split(\n",
        "            inputs[\"df\"].drop('target_column', axis=1),  # Replace 'target_column' with actual target column name\n",
        "            inputs[\"df\"]['target_column'],  # Replace with actual target column name\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define Task for Training the Model\n",
        "train_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Model Training Task\n",
        "\n",
        "    1. Train a Linear Regression model using the preprocessed data (X_train, y_train).\n",
        "    2. The model should be trained using the Linear Regression algorithm from sklearn.\n",
        "    \"\"\",\n",
        "    expected_output=\"A trained Linear Regression model.\",\n",
        "    agent=train_agent,\n",
        "    output=[\"trained_model\"],\n",
        "    action=lambda inputs: {\n",
        "        # Train the model\n",
        "        \"trained_model\": LinearRegression().fit(inputs[\"X_train\"], inputs[\"y_train\"])\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define Task for Evaluating the Model\n",
        "eval_task = Task(\n",
        "    description=\"\"\"\\\n",
        "    # Model Evaluation Task\n",
        "\n",
        "    1. Evaluate the trained model using the test data (X_test, y_test).\n",
        "    2. Calculate and return the Mean Squared Error (MSE) and R-squared value.\n",
        "    \"\"\",\n",
        "    expected_output=\"Model evaluation metrics including Mean Squared Error (MSE) and R-squared value.\",\n",
        "    agent=eval_agent,\n",
        "    output=[\"evaluation_metrics\"],\n",
        "    action=lambda inputs: {\n",
        "        # Evaluate the model\n",
        "        \"evaluation_metrics\": {\n",
        "            \"MSE\": mean_squared_error(inputs[\"y_test\"], inputs[\"trained_model\"].predict(inputs[\"X_test\"])),\n",
        "            \"R-squared\": r2_score(inputs[\"y_test\"], inputs[\"trained_model\"].predict(inputs[\"X_test\"]))\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define the workflow and provide configuration explicitly\n",
        "def main():\n",
        "    crew = Crew(\n",
        "        agents=[preprocess_agent, train_agent, eval_agent],\n",
        "        tasks=[preprocess_task, train_task, eval_task],\n",
        "        verbose=True,  # Enable logging during execution\n",
        "        config={}  # Explicitly pass an empty config if needed\n",
        "    )\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(\"Salary_dataset.csv\")  # Replace with your dataset filename\n",
        "    df = df.dropna()  # Clean the data by dropping rows with missing values\n",
        "\n",
        "    # Define inputs (dataset file path and preprocessed data)\n",
        "    inputs = {\n",
        "        \"df\": df  # Pass the cleaned dataset to the preprocessing task\n",
        "    }\n",
        "\n",
        "    # Execute the workflow\n",
        "    result = crew.kickoff(inputs=inputs)\n",
        "\n",
        "    print(\"\\n\\n########################\")\n",
        "    print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Step 5: Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    result = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "CJk1yS0dryTT",
        "outputId": "54d449ea-b586-4fdc-b30b-8b0fc3524d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for Task\noutput\n  Input should be a valid dictionary or instance of TaskOutput [type=model_type, input_value=['X_train', 'X_test', 'y_train', 'y_test'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c14e2f43385e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Define Task for Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m preprocess_task = Task(\n\u001b[0m\u001b[1;32m     31\u001b[0m     description=\"\"\"\\\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Data Preprocessing Task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Task\noutput\n  Input should be a valid dictionary or instance of TaskOutput [type=model_type, input_value=['X_train', 'X_test', 'y_train', 'y_test'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Al6fLgP1JCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8WIkyJY2Xxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eNXE5Xq2Xmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq --quiet"
      ],
      "metadata": {
        "id": "s7SE8PBD2Xcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize LLM\n",
        "groq_api_key = \"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\"\n",
        "llm_name = \"llama3-70b-8192\"\n",
        "llm = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=llm_name)\n",
        "\n",
        "# Preprocessing agent\n",
        "def preprocess_data(df):\n",
        "    df = df.dropna()  # Handle missing values\n",
        "    X = df.iloc[:, :-1]  # Features\n",
        "    y = df.iloc[:, -1]  # Target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "preprocessor_agent = Agent(\n",
        "    role=\"Data Preprocessor\",\n",
        "    goal=\"Prepare data for ML training by handling missing values and splitting dataset.\",\n",
        "    backstory=\"An experienced data scientist specialized in data cleaning and preprocessing.\"\n",
        ")\n",
        "\n",
        "# Training agent\n",
        "def train_model(X_train, y_train):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "trainer_agent = Agent(\n",
        "    role=\"ML Trainer\",\n",
        "    goal=\"Train an ML model on the provided dataset.\",\n",
        "    backstory=\"A skilled ML engineer with expertise in model training and optimization.\"\n",
        ")\n",
        "\n",
        "# Evaluation agent\n",
        "def evaluate_model(model, X_test, y_test, train_error):\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.scatterplot(x=y_test, y=predictions, alpha=0.7)\n",
        "    plt.xlabel(\"Actual Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(\"Actual vs Predicted Values\")\n",
        "    plt.show()\n",
        "\n",
        "    retrain = mse > train_error * 1.2  # Retrain if test error is significantly higher\n",
        "    return mse, mae, r2, retrain\n",
        "\n",
        "evaluator_agent = Agent(\n",
        "    role=\"Model Evaluator\",\n",
        "    goal=\"Evaluate ML model performance and decide if retraining is needed.\",\n",
        "    backstory=\"A seasoned ML researcher with expertise in model evaluation.\"\n",
        ")\n",
        "\n",
        "# Retraining agent\n",
        "def retrain_model(retrain_flag):\n",
        "    if retrain_flag:\n",
        "        print(\"Retraining the model with adjusted parameters...\")\n",
        "        return False  # Placeholder for retraining logic\n",
        "    return retrain_flag\n",
        "\n",
        "retrainer_agent = Agent(\n",
        "    role=\"Model Retrainer\",\n",
        "    goal=\"Decide when to retrain the model for better accuracy.\",\n",
        "    backstory=\"A data scientist specialized in hyperparameter tuning and model optimization.\"\n",
        ")\n",
        "\n",
        "# Tasks\n",
        "data_preprocessing_task = Task(\n",
        "    description=\"Clean the dataset, remove missing values, and split into train-test sets.\",\n",
        "    agent=preprocessor_agent,\n",
        "    expected_output=\"Preprocessed data with training and test sets.\"\n",
        ")\n",
        "\n",
        "model_training_task = Task(\n",
        "    description=\"Train a Linear Regression model on the preprocessed data.\",\n",
        "    agent=trainer_agent,\n",
        "    expected_output=\"A trained Linear Regression model.\"\n",
        ")\n",
        "\n",
        "model_evaluation_task = Task(\n",
        "    description=\"Evaluate the trained model and determine if retraining is required.\",\n",
        "    agent=evaluator_agent,\n",
        "    expected_output=\"Evaluation metrics (MSE, MAE, R2 score) and retraining decision.\"\n",
        ")\n",
        "\n",
        "model_retraining_task = Task(\n",
        "    description=\"Retrain the model if necessary to improve accuracy.\",\n",
        "    agent=retrainer_agent,\n",
        "    expected_output=\"Retrained model or confirmation that no retraining was needed.\"\n",
        ")\n",
        "\n",
        "# Crew setup with the Groq LLM passed explicitly\n",
        "ml_crew = Crew(\n",
        "    agents=[preprocessor_agent, trainer_agent, evaluator_agent, retrainer_agent],\n",
        "    tasks=[data_preprocessing_task, model_training_task, model_evaluation_task, model_retraining_task],\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Example dataset usage\n",
        "df = pd.read_csv(\"Salary_dataset.csv\")\n",
        "X_train, X_test, y_train, y_test = preprocess_data(df)\n",
        "model = train_model(X_train, y_train)\n",
        "train_error = mean_squared_error(y_train, model.predict(X_train))\n",
        "mse, mae, r2, retrain_flag = evaluate_model(model, X_test, y_test, train_error)\n",
        "retrain_model(retrain_flag)\n",
        "\n",
        "# Execute the crew workflow\n",
        "ml_crew.kickoff()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IV3-VMNB2XRg",
        "outputId": "88f8bdbb-e8c9-4dc3-e31c-9465517a8eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAE8CAYAAAD0XQfXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASrVJREFUeJzt3XlUU9f2B/BvGBLCkAQQCCijohRLnXhSnFv5iZU6v2p5OFuH1tZaW6v+rKLPWq3awbZaa18rVq0DdWjrWB4OOCBOCKIUUVFUBCtTQJAp+/eHK/fnbRAThTC4P2tlLXPPzjn7JCHbe3Nyr4SICIwxxlgdM6vvBBhjjD0buOAwxhgzCS44jDHGTIILDmOMMZPggsMYY8wkuOAwxhgzCS44jDHGTIILDmOMMZPggsMYY8wkuOCwZ4ZEIsH8+fPrO41616tXL/Tq1Uu4f+3aNUgkEkRFRdVbTn/39xxNZcyYMfDy8jL5uM8KLjjsiaxatQoSiQRBQUFP3EdWVhbmz5+Pc+fO1V5iDdyhQ4cgkUiEm6WlJXx8fDBq1ChcvXq1vtMzyvHjxzF//nwUFBSYfOyzZ89CIpHgo48+emRMeno6JBIJpk+fbsLMWE244LAnsnHjRnh5eeHkyZO4fPnyE/WRlZWFBQsWPFMFR2fq1KlYv3491qxZg7CwMGzZsgX/+Mc/kJWVZfJcPD09UVpaipEjRxr1uOPHj2PBggX1UnA6duwIPz8/bNq06ZExP//8MwBgxIgRpkqLPQYXHGa0jIwMHD9+HJ9//jmcnJywcePG+k6p0enevTtGjBiBsWPH4uuvv8by5cuRl5eHdevWPfIx9+7dq5NcJBIJrKysYG5uXif915WIiAhcvXoVJ06cqLZ906ZN8PPzQ8eOHU2cGXsULjjMaBs3boS9vT3CwsLwz3/+85EFp6CgAO+99x68vLwgk8nQokULjBo1Cnfv3sWhQ4fwj3/8AwAwduxY4RCT7nsELy8vjBkzRq/Pvx/bLy8vx7x589CpUycolUrY2Nige/fuOHjwoNHzysnJgYWFBRYsWKDXlpaWBolEgm+++QYAUFFRgQULFsDX1xdWVlZwdHREt27dEBMTY/S4APDyyy8DeFDMAWD+/PmQSCS4ePEi/vWvf8He3h7dunUT4jds2IBOnTpBLpfDwcEBr7/+Om7cuKHX75o1a9CyZUvI5XJ07twZR44c0Yt51Hc4f/75J4YNGwYnJyfI5XK0adMGc+bMEfKbMWMGAMDb21t4/a5du1YnOVYnIiICwP/vyTzszJkzSEtLE2J+/fVXhIWFwc3NDTKZDC1btsTChQtRVVVV4xi6Q6CHDh0Sba/pOfvnP/8JBwcHWFlZITAwEL/99psoprbfO40JFxxmtI0bN2LIkCGQSqUIDw9Heno6Tp06JYopLi5G9+7d8fXXX6NPnz5YsWIFJk+ejD///BM3b97Ec889h3//+98AgIkTJ2L9+vVYv349evToYVQuGo0G//nPf9CrVy98+umnmD9/Pv766y+EhoYafajOxcUFPXv2xNatW/XatmzZAnNzc7z22msAHnzgLliwAC+99BK++eYbzJkzBx4eHjh79qxRY+pcuXIFAODo6Cja/tprr6GkpASffPIJJkyYAABYtGgRRo0aBV9fX3z++eeYNm0aYmNj0aNHD9HhrR9++AGTJk2CWq3G0qVL0bVrVwwYMKDaD/2/S05ORlBQEA4cOIAJEyZgxYoVGDRoEH7//XcAwJAhQxAeHg4A+OKLL4TXz8nJyWQ5ent7o0uXLti6date4dAVoX/9618AgKioKNja2mL69OlYsWIFOnXqhHnz5mHWrFmPHcdQFy5cwIsvvojU1FTMmjULn332GWxsbDBo0CDs2LFDiKvt906jQowZ4fTp0wSAYmJiiIhIq9VSixYt6N133xXFzZs3jwDQ9u3b9frQarVERHTq1CkCQGvXrtWL8fT0pNGjR+tt79mzJ/Xs2VO4X1lZSWVlZaKY/Px8cnFxoXHjxom2A6DIyMga5/fdd98RADp//rxou7+/P7388svC/Xbt2lFYWFiNfVXn4MGDBIB+/PFH+uuvvygrK4t2795NXl5eJJFI6NSpU0REFBkZSQAoPDxc9Phr166Rubk5LVq0SLT9/PnzZGFhIWwvLy8nZ2dnat++vej5WbNmDQEQPYcZGRl6r0OPHj3Izs6Orl+/LhpH99oRES1btowAUEZGRp3n+CgrV64kALR//35hW1VVFTVv3pyCg4OFbSUlJXqPnTRpEllbW9P9+/eFbaNHjyZPT0/hvu71OnjwoOix1T1nvXv3poCAAFF/Wq2WunTpQr6+vsK2J33vNAW8h8OMsnHjRri4uOCll14C8OD4//Dhw7F582bR/zK3bduGdu3aYfDgwXp9SCSSWsvH3NwcUqkUAKDVapGXl4fKykoEBgY+0f8YhwwZAgsLC2zZskXYlpKSgosXL2L48OHCNpVKhQsXLiA9Pf2J8h43bhycnJzg5uaGsLAw3Lt3D+vWrUNgYKAobvLkyaL727dvh1arxbBhw3D37l3hplar4evrKxxKPH36NO7cuYPJkycLzw/wYNmvUqmsMbe//voLcXFxGDduHDw8PERthrx2pshRZ/jw4bC0tBQdVjt8+DBu3bolHE4DALlcLvy7qKgId+/eRffu3VFSUoI///zToLFqkpeXhwMHDmDYsGFC/3fv3kVubi5CQ0ORnp6OW7duAXj6905jxgWHGayqqgqbN2/GSy+9hIyMDFy+fBmXL19GUFAQcnJyEBsbK8ReuXIFzz//vEnyWrduHV544QXheLiTkxN2796NwsJCo/tq1qwZevfuLTqstmXLFlhYWGDIkCHCtn//+98oKChA69atERAQgBkzZiA5OdngcebNm4eYmBgcOHAAycnJyMrKqnaVmLe3t+h+eno6iAi+vr5wcnIS3VJTU3Hnzh0AwPXr1wEAvr6+osfrlmHXRLc8+0lfP1PkqOPo6IjQ0FDs2LED9+/fB/DgcJqFhQWGDRsmxF24cAGDBw+GUqmEQqGAk5OTsHrtSd4nf3f58mUQEebOnas358jISAAQ5v20753GzKK+E2CNx4EDB3D79m1s3rwZmzdv1mvfuHEj+vTpUytjPep/0lVVVaLVVBs2bMCYMWMwaNAgzJgxA87OzjA3N8fixYuF70WM9frrr2Ps2LE4d+4c2rdvj61bt6J3795o1qyZENOjRw9cuXIFv/76K/744w/85z//wRdffIHVq1fjjTfeeOwYAQEBCAkJeWzcw/8zBx7sxUkkEuzdu7faVWW2trYGzLBumTrHESNGYNeuXdi1axcGDBiAbdu2oU+fPsL3SQUFBejZsycUCgX+/e9/o2XLlrCyssLZs2cxc+ZMaLXaR/Zd0/vwYbo+PvjgA4SGhlb7mFatWgF4+vdOY8YFhxls48aNcHZ2xsqVK/Xatm/fjh07dmD16tWQy+Vo2bIlUlJSauyvpsMz9vb21f6+4/r166L//f7yyy/w8fHB9u3bRf3p/lf5JAYNGoRJkyYJh9UuXbqE2bNn68U5ODhg7NixGDt2LIqLi9GjRw/Mnz+/Tj80WrZsCSKCt7c3Wrdu/cg4T09PAA/2NnQr4IAHK6QyMjLQrl27Rz5W9/w+6etnihwfNmDAANjZ2eHnn3+GpaUl8vPzRYfTDh06hNzcXGzfvl20KEW3IrAm9vb2AKD3XtTtnenonjNLS0uD/iNRH++dhoAPqTGDlJaWYvv27Xj11Vfxz3/+U+/29ttvo6ioSFgCOnToUCQlJYlW5+gQEQDAxsYGgP4fM/DgQ+vEiRMoLy8Xtu3atUtv9ZLuf9C6PgEgISEB8fHxTzxXlUqF0NBQbN26FZs3b4ZUKsWgQYNEMbm5uaL7tra2aNWqFcrKyp54XEMMGTIE5ubmWLBggWjOwIPnQJdXYGAgnJycsHr1atFzGBUV9dgfajo5OaFHjx748ccfkZmZqTeGzqNeP1Pk+DC5XI7Bgwdjz549+Pbbb2FjY4OBAwcK7dW9R8rLy7Fq1arH9u3p6Qlzc3PExcWJtv/9sc7OzujVqxe+++473L59W6+fv/76S/h3fb13GgLew2EG+e2331BUVIQBAwZU2/7iiy8KPwIdPnw4ZsyYgV9++QWvvfYaxo0bh06dOiEvLw+//fYbVq9ejXbt2qFly5ZQqVRYvXo17OzsYGNjg6CgIHh7e+ONN97AL7/8gr59+2LYsGG4cuUKNmzYgJYtW4rGffXVV7F9+3YMHjwYYWFhyMjIwOrVq+Hv74/i4uInnu/w4cMxYsQIrFq1CqGhoVCpVKJ2f39/9OrVC506dYKDgwNOnz6NX375BW+//fYTj2mIli1b4uOPP8bs2bNx7do1DBo0CHZ2dsjIyMCOHTswceJEfPDBB7C0tMTHH3+MSZMm4eWXX8bw4cORkZGBtWvXGvT9yFdffYVu3bqhY8eOmDhxIry9vXHt2jXs3r1bWG7eqVMnAMCcOXPw+uuvw9LSEv379zdZjg8bMWIEfvrpJ+zfvx8RERFCMQSALl26wN7eHqNHj8bUqVMhkUiwfv16vWJYHaVSiddeew1ff/01JBIJWrZsiV27dgnfxzxs5cqV6NatGwICAjBhwgT4+PggJycH8fHxuHnzJpKSkgDU33unQaiPpXGs8enfvz9ZWVnRvXv3HhkzZswYsrS0pLt37xIRUW5uLr399tvUvHlzkkql1KJFCxo9erTQTkT066+/kr+/P1lYWOgtM/3ss8+oefPmJJPJqGvXrnT69Gm9ZdFarZY++eQT8vT0JJlMRh06dKBdu3bpLW8lMmxZtI5GoyG5XE4AaMOGDXrtH3/8MXXu3JlUKhXJ5XLy8/OjRYsWUXl5eY396pbZRkdH1xinWxb9119/Vdu+bds26tatG9nY2JCNjQ35+fnRlClTKC0tTRS3atUq8vb2JplMRoGBgRQXF6f3HFa3xJeIKCUlhQYPHkwqlYqsrKyoTZs2NHfuXFHMwoULqXnz5mRmZqa3RLo2c3ycyspKcnV1JQC0Z88evfZjx47Riy++SHK5nNzc3OjDDz+k/fv36y15ru5989dff9HQoUPJ2tqa7O3tadKkSZSSklLtc3blyhUaNWoUqdVqsrS0pObNm9Orr75Kv/zyixDzpO+dpkBCZECZZ4wxxp4Sf4fDGGPMJLjgMMYYMwkuOIwxxkyCCw5jjDGT4ILDGGPMJLjgMMYYMwn+4acJabVaZGVlwc7OrlbPmMwYY/WFiFBUVAQ3NzeYmdW8D8MFx4SysrLg7u5e32kwxlitu3HjBlq0aFFjDBccE7KzswPw4IVRKBT1nA1jjD09jUYDd3d34fOtJlxwTEh3GE2hUHDBYYw1KYZ8TcCLBhhjjJkEFxzGGGMmwQWHMcaYSfB3OIwx9ozQlFbgZn4Jiu5Xws7KAi3sraGQW5psfC44jDH2DMjMvYe1x64hM69E2ObpaI0xXbzg4WhTwyNrDx9SY4yxJk5TWqFXbADgem4Joo5fg6a0wiR5cMFhjLEm7mZ+iV6x0bmeW4Kb+dW31TYuOIwx1sQV3a98qvbawgWHMcaaODurmr+uf1x7beGCwxhjTVwLe2t4OlpX2+bpaI0W9tW31TYuOIwx1sQp5JYY08VLr+joVqmZamk0L4tmjLFngIejDaaFtObf4TDGGKt7Crkl/OXKehufD6kxxhgzCS44jDHGTIILDmOMMZPggsMYY8wkuOAwxhgzCS44jDHGTIILDmOMMZPggsMYY8wkuOAwxhgzCS44jDHGTIILDmOMMZPggsMYY8wk6rXgxMXFoX///nBzc4NEIsHOnTtF7du3b0efPn3g6OgIiUSCc+fO6fVx//59TJkyBY6OjrC1tcXQoUORk5MjisnMzERYWBisra3h7OyMGTNmoLJSfIW7Q4cOoWPHjpDJZGjVqhWioqL0xlq5ciW8vLxgZWWFoKAgnDx58mmfAsYYe2bUa8G5d+8e2rVrh5UrVz6yvVu3bvj0008f2cd7772H33//HdHR0Th8+DCysrIwZMgQob2qqgphYWEoLy/H8ePHsW7dOkRFRWHevHlCTEZGBsLCwvDSSy/h3LlzmDZtGt544w3s379fiNmyZQumT5+OyMhInD17Fu3atUNoaCju3LlTC88EY4w9A6iBAEA7duyoti0jI4MAUGJiomh7QUEBWVpaUnR0tLAtNTWVAFB8fDwREe3Zs4fMzMwoOztbiPn2229JoVBQWVkZERF9+OGH1LZtW1Hfw4cPp9DQUOF+586dacqUKcL9qqoqcnNzo8WLFxs8x8LCQgJAhYWFBj+GMcYaMmM+1xr1dzhnzpxBRUUFQkJChG1+fn7w8PBAfHw8ACA+Ph4BAQFwcXERYkJDQ6HRaHDhwgUh5uE+dDG6PsrLy3HmzBlRjJmZGUJCQoSY6pSVlUGj0YhujDH2rGrUBSc7OxtSqRQqlUq03cXFBdnZ2ULMw8VG165rqylGo9GgtLQUd+/eRVVVVbUxuj6qs3jxYiiVSuHm7u7+RPNkjLGmoFEXnIZu9uzZKCwsFG43btyo75QYY6zeNOpLTKvVapSXl6OgoEC0l5OTkwO1Wi3E/H01mW4V28Mxf1/ZlpOTA4VCAblcDnNzc5ibm1cbo+ujOjKZDDKZ7InnxxhjTUmj3sPp1KkTLC0tERsbK2xLS0tDZmYmgoODAQDBwcE4f/68aDVZTEwMFAoF/P39hZiH+9DF6PqQSqXo1KmTKEar1SI2NlaIYYwxVrN63cMpLi7G5cuXhfsZGRk4d+4cHBwc4OHhgby8PGRmZiIrKwvAg2ICPNgjUavVUCqVGD9+PKZPnw4HBwcoFAq88847CA4OxosvvggA6NOnD/z9/TFy5EgsXboU2dnZ+OijjzBlyhRh72Py5Mn45ptv8OGHH2LcuHE4cOAAtm7dit27dwu5TZ8+HaNHj0ZgYCA6d+6ML7/8Evfu3cPYsWNN9XQxxljjZoJVc4908OBBAqB3Gz16NBERrV27ttr2yMhIoY/S0lJ66623yN7enqytrWnw4MF0+/Zt0TjXrl2jV155heRyOTVr1ozef/99qqio0Mulffv2JJVKycfHh9auXauX79dff00eHh4klUqpc+fOdOLECaPmy8uiGWNNjTGfaxIiovopdc8ejUYDpVKJwsJCKBSK+k6HMcaemjGfa436OxzGGGONBxccxhhjJsEFhzHGmElwwWGMMWYSXHAYY4yZBBccxhhjJsEFhzHGmElwwWGMMWYSXHAYY4yZBBccxhhjJsEFhzHGmElwwWGMMWYSXHAYY4yZBBccxhhjJtGoLzHNGGPs6WlKK3AzvwRF9ythZ2WBFvbWUMgta30cLjiMMfYMy8y9h7XHriEzr0TY5ulojTFdvODhaFOrY/EhNcYYe0ZpSiv0ig0AXM8tQdTxa9CUVtTqeFxwGGPsGXUzv0Sv2Ohczy3Bzfzq254UFxzGGHtGFd2vfKp2Y3HBYYyxZ5SdVc1f4z+u3VhPXXA0Gg127tyJ1NTU2siHMcaYibSwt4ano3W1bZ6O1mhhX33bkzK64AwbNgzffPMNAKC0tBSBgYEYNmwYXnjhBWzbtq1Wk2OMMVZ3FHJLjOnipVd0dKvUantptNH7S3FxcZgzZw4AYMeOHSAiFBQUYN26dfj4448xdOjQWk2QMcZY3fFwtMG0kNYm+R2O0Xs4hYWFcHBwAADs27cPQ4cOhbW1NcLCwpCenm5UX3Fxcejfvz/c3NwgkUiwc+dOUTsRYd68eXB1dYVcLkdISIjeGHl5eYiIiIBCoYBKpcL48eNRXFwsiklOTkb37t1hZWUFd3d3LF26VC+X6Oho+Pn5wcrKCgEBAdizZ4/RuTDGWGOkkFvC302JIB9H+Lsp66TYAE9QcNzd3REfH4979+5h37596NOnDwAgPz8fVlZWRvV17949tGvXDitXrqy2fenSpfjqq6+wevVqJCQkwMbGBqGhobh//74QExERgQsXLiAmJga7du1CXFwcJk6cKLRrNBr06dMHnp6eOHPmDJYtW4b58+djzZo1Qszx48cRHh6O8ePHIzExEYMGDcKgQYOQkpJiVC6MMcZqQEZauXIlWVhYkEqlohdeeIGqqqqIiOirr76iXr16GdudAADt2LFDuK/VakmtVtOyZcuEbQUFBSSTyWjTpk1ERHTx4kUCQKdOnRJi9u7dSxKJhG7dukVERKtWrSJ7e3sqKysTYmbOnElt2rQR7g8bNozCwsJE+QQFBdGkSZMMzsUQhYWFBIAKCwsNfgxjjDVkxnyuGb2H89ZbbyE+Ph4//vgjjh07BjOzB134+Pjg448/rrVCmJGRgezsbISEhAjblEolgoKCEB8fDwCIj4+HSqVCYGCgEBMSEgIzMzMkJCQIMT169IBUKhViQkNDkZaWhvz8fCHm4XF0MbpxDMmlOmVlZdBoNKIbY4w9q55oWXRgYCDCwsJw69YtVFY++GFQWFgYunbtWmuJZWdnAwBcXFxE211cXIS27OxsODs7i9otLCzg4OAgiqmuj4fHeFTMw+2Py6U6ixcvhlKpFG7u7u6PmTVjjDVdRheckpISjB8/HtbW1mjbti0yMzMBAO+88w6WLFlS6wk2ZrNnz0ZhYaFwu3HjRn2nxBhj9cbogjN79mwkJSXh0KFDokUCISEh2LJlS60lplarAQA5OTmi7Tk5OUKbWq3GnTt3RO2VlZXIy8sTxVTXx8NjPCrm4fbH5VIdmUwGhUIhujHG2LPK6IKzc+dOfPPNN+jWrRskEomwvW3btrhy5UqtJebt7Q21Wo3Y2Fhhm0ajQUJCAoKDgwEAwcHBKCgowJkzZ4SYAwcOQKvVIigoSIiJi4tDRcX/n/U0JiYGbdq0gb29vRDz8Di6GN04huTCGGPsMYxdkSCXy+nKlStERGRrayv8+9y5c6RQKIzqq6ioiBITEykxMZEA0Oeff06JiYl0/fp1IiJasmQJqVQq+vXXXyk5OZkGDhxI3t7eVFpaKvTRt29f6tChAyUkJNDRo0fJ19eXwsPDhfaCggJycXGhkSNHUkpKCm3evJmsra3pu+++E2KOHTtGFhYWtHz5ckpNTaXIyEiytLSk8+fPCzGG5PI4vEqNMdbUGPO5ZnTB6d69O3311VdE9KDgXL16lYiI3n77bQoNDTWqr4MHDxIAvdvo0aOJ6MFy5Llz55KLiwvJZDLq3bs3paWlifrIzc2l8PBwsrW1JYVCQWPHjqWioiJRTFJSEnXr1o1kMhk1b96clixZopfL1q1bqXXr1iSVSqlt27a0e/duUbshuTwOFxzGWFNjzOeahIjImD2io0eP4pVXXsGIESMQFRWFSZMm4eLFizh+/DgOHz6MTp061e4uWBOi0WigVCpRWFjI3+cwxpoEYz7XjP4Op1u3bjh37hwqKysREBCAP/74A87OzoiPj+diwxhj7JGM3sNhT473cBhjTY0xn2tGny1a97ubR/Hw8DC2S8YYY88AowuOl5eXaDn031VVVT1VQowxxpomowtOYmKi6H5FRQUSExPx+eefY9GiRbWWGGOMsabF6ILTrl07vW2BgYFwc3PDsmXLMGTIkFpJjDHGWNPyRCfvrE6bNm1w6tSp2uqOMcZYE2P0Hs7fT7FPRLh9+zbmz58PX1/fWkuMMcZY02J0wVGpVHqLBogI7u7u2Lx5c60lxhhjrGkxuuAcPHhQdN/MzAxOTk5o1aoVLCyM7o4xxtgzwugK0bNnz7rIgzHGWBNnUMH57bffDO5wwIABT5wMY4yxpsuggjNo0CCDOpNIJPzDT8YYY9UyqOBotdq6zoMxxlgTV2u/w2GMMcZq8kTLyu7du4fDhw8jMzMT5eXlorapU6fWSmKMMcaalic6l1q/fv1QUlKCe/fuwcHBAXfv3oW1tTWcnZ254DDGGKuW0YfU3nvvPfTv3x/5+fmQy+U4ceIErl+/jk6dOmH58uV1kSNjjLEmwOiCc+7cObz//vswMzODubk5ysrK4O7ujqVLl+J///d/6yJHxhhjTYDRBcfS0hJmZg8e5uzsLFyQTalU4saNG7WbHWOMsSbD6O9wOnTogFOnTsHX1xc9e/bEvHnzcPfuXaxfvx7PP/98XeTIGGOsCTB4D0f3g85PPvkErq6uAIBFixbB3t4eb775Jv766y+sWbOmbrJkjDHW6Bm8h9O8eXOMGTMG48aNQ2BgIIAHh9T27dtXZ8kxxhhrOgzew5kyZQp++eUXPPfcc+jevTuioqJQUlJSl7kxxhhrQgwuOHPnzsXly5cRGxsLHx8fvP3223B1dcWECROQkJBQZwkWFRVh2rRp8PT0hFwuR5cuXURXFiUizJs3D66urpDL5QgJCUF6erqoj7y8PEREREChUEClUmH8+PEoLi4WxSQnJ6N79+6wsrISVt39XXR0NPz8/GBlZYWAgADs2bOnbibNGGNNET2hoqIi+v7776lr164kkUjI39+fPvvssyft7pGGDRtG/v7+dPjwYUpPT6fIyEhSKBR08+ZNIiJasmQJKZVK2rlzJyUlJdGAAQPI29ubSktLhT769u1L7dq1oxMnTtCRI0eoVatWFB4eLrQXFhaSi4sLRUREUEpKCm3atInkcjl99913QsyxY8fI3Nycli5dShcvXqSPPvqILC0t6fz58wbPpbCwkABQYWFhLTwzjDFW/4z5XHvigvOwXbt2kYODA5mZmdVGd4KSkhIyNzenXbt2ibZ37NiR5syZQ1qtltRqNS1btkxoKygoIJlMRps2bSIioosXLxIAOnXqlBCzd+9ekkgkdOvWLSIiWrVqFdnb21NZWZkQM3PmTGrTpo1wf9iwYRQWFibKIygoiCZNmmTwfLjgMMaaGmM+15745J0lJSWIiopCz549MWDAADg6OmLRokW1tN/1QGVlJaqqqmBlZSXaLpfLcfToUWRkZCA7OxshISFCm1KpRFBQEOLj4wEA8fHxUKlUwkIHAAgJCYGZmZlwKDA+Ph49evSAVCoVYkJDQ5GWlob8/Hwh5uFxdDG6capTVlYGjUYjujHG2LPK6IJz/PhxvPHGG3B1dcWUKVPg5eWFgwcP4tKlS5g1a1atJmdnZ4fg4GAsXLgQWVlZqKqqwoYNGxAfH4/bt28jOzsbAODi4iJ6nIuLi9CWnZ0NZ2dnUbuFhQUcHBxEMdX1oWurKUbXXp3FixdDqVQKN3d3d2OfAsYYazIMLjhLly4VVqidP38ey5YtQ3Z2NtatW4cePXrUWYLr168HEaF58+aQyWT46quvEB4eLpztoCGbPXs2CgsLhRufiYEx9iwz+Hc4y5Ytw4gRIxAdHW3SMwq0bNkShw8fxr1796DRaODq6orhw4fDx8cHarUaAJCTkyP8GFV3v3379gAAtVqNO3fuiPqsrKxEXl6e8Hi1Wo2cnBxRjO7+42J07dWRyWSQyWRPMGvGGGt6DN5NyMrKwhdffFFvp6+xsbGBq6sr8vPzsX//fgwcOBDe3t5Qq9WIjY0V4jQaDRISEhAcHAwACA4ORkFBAc6cOSPEHDhwAFqtFkFBQUJMXFwcKioqhJiYmBi0adMG9vb2QszD4+hidOMwxhh7jLpfw/B09u3bR3v37qWrV6/SH3/8Qe3ataOgoCAqLy8nogfLolUqFf3666+UnJxMAwcOrHZZdIcOHSghIYGOHj1Kvr6+omXRBQUF5OLiQiNHjqSUlBTavHkzWVtb6y2LtrCwoOXLl1NqaipFRkbysmjG2DPP5Mui69KWLVvIx8eHpFIpqdVqmjJlChUUFAjtWq2W5s6dSy4uLiSTyah3796UlpYm6iM3N5fCw8PJ1taWFAoFjR07loqKikQxSUlJ1K1bN5LJZNS8eXNasmSJXi5bt26l1q1bk1QqpbZt29Lu3buNmgsXHMZYU2PM55qEiKh+97GeHRqNBkqlEoWFhVAoFPWdDmOMPTVjPtca/lIvxhhjTYJBq9SM+cEi/8+dMcZYdQwqOCqVChKJxKAOddfNYYwxxh5mUME5ePCg8O9r165h1qxZGDNmjLAkOD4+HuvWrcPixYvrJkvGGGONntGLBnr37o033ngD4eHhou0///wz1qxZg0OHDtVmfk0KLxpgjDU1dbpoID4+XnQiTJ3AwECcPHnS2O4YY4w9I4wuOO7u7vj+++/1tv/nP//hk1Myxhh7JIPPpabzxRdfYOjQodi7d69wapiTJ08iPT0d27Ztq/UEGWOMNQ1G7+H069cPly5dQv/+/ZGXl4e8vDz0798fly5dQr9+/eoiR8YYY00An2nAhHjRAGOsqanzMw0cOXIEI0aMQJcuXXDr1i0AD65bc/To0SfpjjHG2DPA6IKzbds2hIaGQi6X4+zZsygrKwMAFBYW4pNPPqn1BBljjDUNRhecjz/+GKtXr8b3338PS0tLYXvXrl1x9uzZWk2OMcZY02F0wUlLS6v2ktJKpRIFBQW1kRNjjLEmyOiCo1arcfnyZb3tR48ehY+PT60kxRhjrOkxuuBMmDAB7777LhISEiCRSJCVlYWNGzfigw8+wJtvvlkXOTLGGGsCjP7h56xZs6DVatG7d2+UlJSgR48ekMlk+OCDD/DOO+/URY6MMcaagCf+HU55eTkuX76M4uJi+Pv7w9bWtrZza3L4dziMsaamTn+HM27cOBQVFUEqlcLf3x+dO3eGra0t7t27h3Hjxj1x0owxxpo2owvOunXrUFpaqre9tLQUP/30U60kxRhjrOkx+DscjUYDIgIRoaioCFZWVkJbVVUV9uzZA2dn5zpJkjHGWONncMHRXWZaIpGgdevWeu0SiQQLFiyo1eQYY4w1HQYXnIMHD4KI8PLLL2Pbtm1wcHAQ2qRSKTw9PeHm5lYnSTLGGGv8DP4Op2fPnujVqxcyMjIwaNAg9OzZU7gFBwfXSbGpqqrC3Llz4e3tDblcjpYtW2LhwoV4eGEdEWHevHlwdXWFXC5HSEgI0tPTRf3k5eUhIiICCoUCKpUK48ePR3FxsSgmOTkZ3bt3h5WVFdzd3bF06VK9fKKjo+Hn5wcrKysEBARgz549tT5nxhhrsshIP/74I23dulVv+9atWykqKsrY7mq0aNEicnR0pF27dlFGRgZFR0eTra0trVixQohZsmQJKZVK2rlzJyUlJdGAAQPI29ubSktLhZi+fftSu3bt6MSJE3TkyBFq1aoVhYeHC+2FhYXk4uJCERERlJKSQps2bSK5XE7fffedEHPs2DEyNzenpUuX0sWLF+mjjz4iS0tLOn/+vMHzKSwsJABUWFj4lM8MY4w1DMZ8rhldcHx9fenAgQN62w8dOkStW7c2trsahYWF0bhx40TbhgwZQhEREUREpNVqSa1W07Jly4T2goICkslktGnTJiIiunjxIgGgU6dOCTF79+4liURCt27dIiKiVatWkb29PZWVlQkxM2fOpDZt2gj3hw0bRmFhYaJcgoKCaNKkSQbPhwsOY6ypMeZzzehl0ZmZmfD29tbb7unpiczMzKfd4RLp0qULYmNjcenSJQBAUlISjh49ildeeQUAkJGRgezsbISEhAiPUSqVCAoKQnx8PAAgPj4eKpUKgYGBQkxISAjMzMyQkJAgxPTo0QNSqVSICQ0NRVpaGvLz84WYh8fRxejGqU5ZWRk0Go3oxhhjzyqjC46zszOSk5P1ticlJcHR0bFWktKZNWsWXn/9dfj5+cHS0hIdOnTAtGnTEBERAQDIzs4GALi4uIge5+LiIrRlZ2frLde2sLCAg4ODKKa6Ph4e41ExuvbqLF68GEqlUri5u7sbNX/GGGtKjC444eHhmDp1Kg4ePIiqqipUVVXhwIEDePfdd/H666/XanJbt27Fxo0b8fPPP+Ps2bNYt24dli9fjnXr1tXqOHVl9uzZKCwsFG43btyo75QYY6zeGH3yzoULF+LatWvo3bs3LCwePFyr1WLUqFG1fsXPGTNmCHs5ABAQEIDr169j8eLFGD16NNRqNQAgJycHrq6uwuNycnLQvn17AA8up3Dnzh1Rv5WVlcjLyxMer1arkZOTI4rR3X9cjK69OjKZDDKZzNhpM8ZYk2T0Ho5UKsWWLVvw559/YuPGjdi+fTuuXLmCH3/8UfQdSG0oKSmBmZk4RXNzc2i1WgCAt7c31Go1YmNjhXaNRoOEhAQEBwcDAIKDg1FQUIAzZ84IMQcOHIBWq0VQUJAQExcXh4qKCiEmJiYGbdq0gb29vRDz8Di6GN04jDHGHsMEixie2OjRo6l58+bCsujt27dTs2bN6MMPPxRilixZQiqVin799VdKTk6mgQMHVrssukOHDpSQkEBHjx4lX19f0bLogoICcnFxoZEjR1JKSgpt3ryZrK2t9ZZFW1hY0PLlyyk1NZUiIyN5WTRj7JlnzOeaQZcnmD59OhYuXAgbGxtMnz69xtjPP/+8lkohUFRUhLlz52LHjh24c+cO3NzcEB4ejnnz5gl7U0SEyMhIrFmzBgUFBejWrRtWrVolOv1OXl4e3n77bfz+++8wMzPD0KFD8dVXX4kuqZCcnIwpU6bg1KlTaNasGd555x3MnDlTlE90dDQ++ugjXLt2Db6+vli6dCn69etn8Hz48gSMsabGmM81gwrOSy+9hB07dkClUuGll156dGcSCQ4cOGB8xs8ILjiMsaam1gsOqx1ccBhjTU2dXoCNMcYYexIGLYseMmSIwR1u3779iZNhjDHWdBm0h/Pwr+UVCgViY2Nx+vRpof3MmTOIjY2FUqmss0QZY4w1bgbt4axdu1b498yZMzFs2DCsXr0a5ubmAB5cRuCtt97i7yUYY4w9ktGLBpycnHD06FG0adNGtD0tLQ1dunRBbm5urSbYlPCiAcZYU1OniwYqKyvx559/6m3/888/hTMAMMYYY39n9LnUxo4di/Hjx+PKlSvo3LkzACAhIQFLlizB2LFjaz1BxhhjTYPRBWf58uVQq9X47LPPcPv2bQCAq6srZsyYgffff7/WE2SMMdY0PNUPP3UXFOPvIwzD3+EwxpqaOv/hZ2VlJf773/9i06ZNkEgkAICsrCwUFxc/SXeMMcaeAUYfUrt+/Tr69u2LzMxMlJWV4X/+539gZ2eHTz/9FGVlZVi9enVd5MkYY6yRM3oP591330VgYCDy8/Mhl8uF7YMHD9a7XgxjjDGmY/QezpEjR3D8+HG9i615eXnh1q1btZYYY+wBTWkFbuaXoOh+JeysLNDC3hoKuWV9p8WY0YwuOFqtFlVVVXrbb968CTs7u1pJijH2QGbuPaw9dg2ZeSXCNk9Ha4zp4gUPR5t6zIwx4xl9SK1Pnz748ssvhfsSiQTFxcWIjIw06mJkjLGaaUor9IoNAFzPLUHU8WvQlFY84pGMNUxGF5zly5fj2LFj8Pf3x/379/Gvf/1LOJz26aef1kWOjD2TbuaX6BUbneu5JbiZX30bYw2V0YfU3N3dkZSUhC1btiApKQnFxcUYP348IiIiRIsIGGNPp+h+5VO1M9bQGFVwKioq4Ofnh127diEiIgIRERF1lRdjzzw7q5r/PB/XzlhDY9QhNUtLS9y/f7+ucmGMPaSFvTU8Ha2rbfN0tEYL++rbGGuojP4OZ8qUKfj0009RWcm784zVJYXcEmO6eOkVHd0qNV4azRobo/fJT506hdjYWPzxxx8ICAiAjY14aSZfYpqx2uPhaINpIa35dzisSTC64KhUKgwdOrQucmGMVUMht4S/nC/fzho/owvOw5ebZowxxgxl8Hc4Wq0Wn376Kbp27Yp//OMfmDVrFkpLS+syNwAPTpkjkUj0blOmTAEA3L9/H1OmTIGjoyNsbW0xdOhQ5OTkiPrIzMxEWFgYrK2t4ezsjBkzZuh9B3Xo0CF07NgRMpkMrVq1QlRUlF4uK1euhJeXF6ysrBAUFISTJ0/W2bybOk1pBS5mFSLhai4uZhXyjxgZewYYXHAWLVqE//3f/4WtrS2aN2+OFStWCB/6denUqVO4ffu2cIuJiQEAvPbaawCA9957D7///juio6Nx+PBhZGVlYciQIcLjq6qqEBYWhvLychw/fhzr1q1DVFQU5s2bJ8RkZGQgLCwML730Es6dO4dp06bhjTfewP79+4WYLVu2YPr06YiMjMTZs2fRrl07hIaG4s6dO3X+HDQ1mbn38EXMJXz2xyWsibuKz/64hC//ewmZuffqOzXGWF0iA7Vq1YpWr14t3I+JiSGpVEpVVVWGdlEr3n33XWrZsiVptVoqKCggS0tLio6OFtpTU1MJAMXHxxMR0Z49e8jMzIyys7OFmG+//ZYUCgWVlZUREdGHH35Ibdu2FY0zfPhwCg0NFe537tyZpkyZItyvqqoiNzc3Wrx4scG5FxYWEgAqLCw0btJNSGFJOc3/NYXGrT2pd1vwWwoVlpTXd4qMMSMY87lm8B5OZmam6FxpISEhkEgkyMrKqv0q+Ajl5eXYsGEDxo0bB4lEgjNnzqCiogIhISFCjJ+fHzw8PBAfHw8AiI+PR0BAAFxcXISY0NBQaDQaXLhwQYh5uA9djK6P8vJynDlzRhRjZmaGkJAQIaY6ZWVl0Gg0otuzjk/Xwtizy+CCU1lZCSsrK9E2S0tLVFSY7tj7zp07UVBQgDFjxgAAsrOzIZVKoVKpRHEuLi7Izs4WYh4uNrp2XVtNMRqNBqWlpbh79y6qqqqqjdH1UZ3FixdDqVQKN3d3d6Pn3NTw6VoYe3YZvEqNiDBmzBjIZDJh2/379zF58mTRb3Hq8nc4P/zwA1555RW4ubnV2Ri1afbs2Zg+fbpwX6PRPPNFh0/Xwtizy+C/7tGjR+ttGzFiRK0mU5Pr16/jv//9r6igqdVqlJeXo6CgQLSXk5OTA7VaLcT8fTWZbhXbwzF/X9mWk5MDhUIBuVwOc3NzmJubVxuj66M6MplMVKDZ/5+u5Xqu/qEzPl0LY02bwQWnvn9/s3btWjg7OyMsLEzY1qlTJ1haWiI2Nlb4MWpaWhoyMzMRHBwMAAgODsaiRYtw584dODs7AwBiYmKgUCjg7+8vxOzZs0c0XkxMjNCHVCpFp06dEBsbi0GDBgF4sEw8NjYWb7/9dp3Ou6nRna4l6vg1UdHh07Uw9gyo+zUMT6+qqoo8PDxo5syZem2TJ08mDw8POnDgAJ0+fZqCg4MpODhYaK+srKTnn3+e+vTpQ+fOnaN9+/aRk5MTzZ49W4i5evUqWVtb04wZMyg1NZVWrlxJ5ubmtG/fPiFm8+bNJJPJKCoqii5evEgTJ04klUolWv32OLxK7f8VlpTThVsFdOLKXbpwq4BXpzHWSBnzudYoCs7+/fsJAKWlpem1lZaW0ltvvUX29vZkbW1NgwcPptu3b4tirl27Rq+88grJ5XJq1qwZvf/++1RRUSGKOXjwILVv356kUin5+PjQ2rVr9cb6+uuvycPDg6RSKXXu3JlOnDhh1Dy44DDGmhpjPtckRET1uov1DNFoNFAqlSgsLIRCoajvdBhj7KkZ87lm9OUJGGOMsSfBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYyZhUd8JsJppSitwM78ERfcrYWdlgRb21lDILes7LcYYMxoXnAYsM/ce1h67hsy8EmGbp6M1xnTxgoejTT1mxhhjxmvwh9Ru3bqFESNGwNHREXK5HAEBATh9+rTQTkSYN28eXF1dIZfLERISgvT0dFEfeXl5iIiIgEKhgEqlwvjx41FcXCyKSU5ORvfu3WFlZQV3d3csXbpUL5fo6Gj4+fnBysoKAQEB2LNnT91MGg/2bP5ebADgem4Joo5fg6a0os7GZoyxutCgC05+fj66du0KS0tL7N27FxcvXsRnn30Ge3t7IWbp0qX46quvsHr1aiQkJMDGxgahoaG4f/++EBMREYELFy4gJiYGu3btQlxcHCZOnCi0azQa9OnTB56enjhz5gyWLVuG+fPnY82aNULM8ePHER4ejvHjxyMxMRGDBg3CoEGDkJKSUidzv5lfoldsdK7nluBmfvVtjDHWUEmIiOo7iUeZNWsWjh07hiNHjlTbTkRwc3PD+++/jw8++AAAUFhYCBcXF0RFReH1119Hamoq/P39cerUKQQGBgIA9u3bh379+uHmzZtwc3PDt99+izlz5iA7OxtSqVQYe+fOnfjzzz8BAMOHD8e9e/ewa9cuYfwXX3wR7du3x+rVqw2aj0ajgVKpRGFhIRQKRY2xCVdzsSbu6iPbJ/bwQZCPo0HjMsZYXTHmc61B7+H89ttvCAwMxGuvvQZnZ2d06NAB33//vdCekZGB7OxshISECNuUSiWCgoIQHx8PAIiPj4dKpRKKDQCEhITAzMwMCQkJQkyPHj2EYgMAoaGhSEtLQ35+vhDz8Di6GN041SkrK4NGoxHdDGVnVfPXa49rZ4yxhqZBF5yrV6/i22+/ha+vL/bv348333wTU6dOxbp16wAA2dnZAAAXFxfR41xcXIS27OxsODs7i9otLCzg4OAgiqmuj4fHeFSMrr06ixcvhlKpFG7u7u4Gz72FvTU8Ha2rbfN0tEYL++rbGGOsoWrQBUer1aJjx4745JNP0KFDB0ycOBETJkww+BBWfZs9ezYKCwuF240bNwx+rEJuiTFdvPSKjm6VGi+NZow1Ng36uIyrqyv8/f1F25577jls27YNAKBWqwEAOTk5cHV1FWJycnLQvn17IebOnTuiPiorK5GXlyc8Xq1WIycnRxSju/+4GF17dWQyGWQymUFzrY6How2mhbTm3+EwxpqEBr2H07VrV6SlpYm2Xbp0CZ6engAAb29vqNVqxMbGCu0ajQYJCQkIDg4GAAQHB6OgoABnzpwRYg4cOACtVougoCAhJi4uDhUV/7/UOCYmBm3atBFWxAUHB4vG0cXoxqkrCrkl/N2UCPJxhL+bkosNY6zxogbs5MmTZGFhQYsWLaL09HTauHEjWVtb04YNG4SYJUuWkEqlol9//ZWSk5Np4MCB5O3tTaWlpUJM3759qUOHDpSQkEBHjx4lX19fCg8PF9oLCgrIxcWFRo4cSSkpKbR582aytram7777Tog5duwYWVhY0PLlyyk1NZUiIyPJ0tKSzp8/b/B8CgsLCQAVFhY+5TPDGGMNgzGfaw264BAR/f777/T888+TTCYjPz8/WrNmjahdq9XS3LlzycXFhWQyGfXu3ZvS0tJEMbm5uRQeHk62trakUCho7NixVFRUJIpJSkqibt26kUwmo+bNm9OSJUv0ctm6dSu1bt2apFIptW3blnbv3m3UXLjgMMaaGmM+1xr073CaGmPWqzPGWGPQZH6HwxhjrOnggsMYY8wkuOAwxhgzCS44jDHGTIILDmOMMZNo0GcaYA0PX4GUMfakuOAwg/EVSBljT4MPqTGD8BVIGWNPiwsOMwhfgZQx9rS44DCDFN2vfKp2xhjjgsMMwlcgZYw9LS44zCB8BVLG2NPigsMMwlcgZYw9LT4OwgzGVyBljD0NLjjMKAq5JfzlyvpOgzHWCPEhNcYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQvGjAhIgLw4BrgjDHWFOg+z3SfbzXhgmNCRUVFAAB3d/d6zoQxxmpXUVERlMqaV7BKyJCyxGqFVqtFVlYW7OzsIJFI6nw8jUYDd3d33LhxAwqFos7Hqys8j4ajKcwB4HnUJiJCUVER3NzcYGZW87c0vIdjQmZmZmjRooXJx1UoFI36j0qH59FwNIU5ADyP2vK4PRsdXjTAGGPMJLjgMMYYMwkuOE2YTCZDZGQkZDJZfafyVHgeDUdTmAPA86gvvGiAMcaYSfAeDmOMMZPggsMYY8wkuOAwxhgzCS44jDHGTIILTgNz69YtjBgxAo6OjpDL5QgICMDp06eFdiLCvHnz4OrqCrlcjpCQEKSnp4v6yMvLQ0REBBQKBVQqFcaPH4/i4mJRTHJyMrp37w4rKyu4u7tj6dKlerlER0fDz88PVlZWCAgIwJ49ewyag5eXFyQSid5typQpAID79+9jypQpcHR0hK2tLYYOHYqcnBxRH5mZmQgLC4O1tTWcnZ0xY8YMVFZWimIOHTqEjh07QiaToVWrVoiKitLLZeXKlfDy8oKVlRWCgoJw8uRJg+YAAFVVVZg7dy68vb0hl8vRsmVLLFy4UHTOqMbwehQVFWHatGnw9PSEXC5Hly5dcOrUqQY9h7i4OPTv3x9ubm6QSCTYuXOnqL0h5VxTLo+bx/bt29GnTx84OjpCIpHg3LlzeuM3lr8XgxBrMPLy8sjT05PGjBlDCQkJdPXqVdq/fz9dvnxZiFmyZAkplUrauXMnJSUl0YABA8jb25tKS0uFmL59+1K7du3oxIkTdOTIEWrVqhWFh4cL7YWFheTi4kIRERGUkpJCmzZtIrlcTt99950Qc+zYMTI3N6elS5fSxYsX6aOPPiJLS0s6f/78Y+dx584dun37tnCLiYkhAHTw4EEiIpo8eTK5u7tTbGwsnT59ml588UXq0qWL8PjKykp6/vnnKSQkhBITE2nPnj3UrFkzmj17thBz9epVsra2punTp9PFixfp66+/JnNzc9q3b58Qs3nzZpJKpfTjjz/ShQsXaMKECaRSqSgnJ8eg12PRokXk6OhIu3btooyMDIqOjiZbW1tasWJFo3o9hg0bRv7+/nT48GFKT0+nyMhIUigUdPPmzQY7hz179tCcOXNo+/btBIB27Ngham9IOdeUy+Pm8dNPP9GCBQvo+++/JwCUmJio91w0lr8XQ3DBaUBmzpxJ3bp1e2S7VqsltVpNy5YtE7YVFBSQTCajTZs2ERHRxYsXCQCdOnVKiNm7dy9JJBK6desWERGtWrWK7O3tqaysTDR2mzZthPvDhg2jsLAw0fhBQUE0adIko+f17rvvUsuWLUmr1VJBQQFZWlpSdHS00J6amkoAKD4+nogefNiYmZlRdna2EPPtt9+SQqEQcv7www+pbdu2onGGDx9OoaGhwv3OnTvTlClThPtVVVXk5uZGixcvNijvsLAwGjdunGjbkCFDKCIigogax+tRUlJC5ubmtGvXLtH2jh070pw5cxrFHP7+Qd2QcjYkl0fN42EZGRnVFpzG9PdiCD6k1oD89ttvCAwMxGuvvQZnZ2d06NAB33//vdCekZGB7OxshISECNuUSiWCgoIQHx8PAIiPj4dKpUJgYKAQExISAjMzMyQkJAgxPXr0gFQqFWJCQ0ORlpaG/Px8IebhcXQxunEMVV5ejg0bNmDcuHGQSCQ4c+YMKioqRH37+fnBw8NDNIeAgAC4uLiIxtZoNLhw4YJB+ZWXl+PMmTOiGDMzM4SEhBg8hy5duiA2NhaXLl0CACQlJeHo0aN45ZVXADSO16OyshJVVVWwsrISbZfL5Th69GijmMPfNaScDcnlaTSmvxdDcMFpQK5evYpvv/0Wvr6+2L9/P958801MnToV69atAwBkZ2cDgOiNpbuva8vOzoazs7Oo3cLCAg4ODqKY6vp4eIxHxejaDbVz504UFBRgzJgxQr9SqRQqlarGOTxpfhqNBqWlpbh79y6qqqqeag6zZs3C66+/Dj8/P1haWqJDhw6YNm0aIiIiRLk05NfDzs4OwcHBWLhwIbKyslBVVYUNGzYgPj4et2/fbhRz+LuGlLMhuTyNxvT3Ygg+W3QDotVqERgYiE8++QQA0KFDB6SkpGD16tUYPXp0PWf3ZH744Qe88sorcHNzq+9UjLZ161Zs3LgRP//8M9q2bYtz585h2rRpcHNza1Svx/r16zFu3Dg0b94c5ubm6NixI8LDw3HmzJn6To09Y3gPpwFxdXWFv7+/aNtzzz2HzMxMAIBarQYAvRUqOTk5QptarcadO3dE7ZWVlcjLyxPFVNfHw2M8KkbXbojr16/jv//9L9544w1hm1qtRnl5OQoKCmqcw5Pmp1AoIJfL0axZM5ibmz/VHGbMmCHs5QQEBGDkyJF47733sHjxYlEuDf31aNmyJQ4fPozi4mLcuHEDJ0+eREVFBXx8fBrNHB7WkHI2JJen0Zj+XgzBBacB6dq1K9LS0kTbLl26BE9PTwCAt7c31Go1YmNjhXaNRoOEhAQEBwcDAIKDg1FQUCD63+uBAweg1WoRFBQkxMTFxaGiokKIiYmJQZs2bWBvby/EPDyOLkY3jiHWrl0LZ2dnhIWFCds6deoES0tLUd9paWnIzMwUzeH8+fOiD4yYmBgoFAqhID8uP6lUik6dOolitFotYmNjDZ5DSUmJ3gWlzM3NodVqATS+18PGxgaurq7Iz8/H/v37MXDgwEY3B6BhPe+G5PI0GtPfi0FqbfkBe2onT54kCwsLWrRoEaWnp9PGjRvJ2tqaNmzYIMQsWbKEVCoV/frrr5ScnEwDBw6sdjlohw4dKCEhgY4ePUq+vr6i5aAFBQXk4uJCI0eOpJSUFNq8eTNZW1vrLQe1sLCg5cuXU2pqKkVGRhq8DJfowQoXDw8Pmjlzpl7b5MmTycPDgw4cOECnT5+m4OBgCg4OFtp1yzz79OlD586do3379pGTk1O1yzxnzJhBqamptHLlymqXecpkMoqKiqKLFy/SxIkTSaVSiVbz1GT06NHUvHlzYVn09u3bqVmzZvThhx8KMY3h9di3bx/t3buXrl69Sn/88Qe1a9eOgoKCqLy8vMHOoaioiBITEykxMZEA0Oeff06JiYl0/fr1BpdzTbk8bh65ubmUmJhIu3fvJgC0efNmSkxMpNu3bwv9N5a/F0NwwWlgfv/9d3r++edJJpORn58frVmzRtSu1Wpp7ty55OLiQjKZjHr37k1paWmimNzcXAoPDydbW1tSKBQ0duxYKioqEsUkJSVRt27dSCaTUfPmzWnJkiV6uWzdupVat25NUqmU2rZtS7t37zZ4Hvv37ycAerkREZWWltJbb71F9vb2ZG1tTYMHDxb9gRERXbt2jV555RWSy+XUrFkzev/996miokIUc/DgQWrfvj1JpVLy8fGhtWvX6o319ddfk4eHB0mlUurcuTOdOHHC4DloNBp69913ycPDg6ysrMjHx4fmzJkjWkbbGF6PLVu2kI+PD0mlUlKr1TRlyhQqKCho0HM4ePAgAdC7jR49usHlXFMuj5vH2rVrq22PjIwU+m8sfy+G4MsTMMYYMwn+DocxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYexRq66SxfXtl69emHatGl1OgZr+rjgMGag+Ph4mJubi05GaigvLy98+eWXtZ/UY/Tv3x99+/attu3IkSOQSCRITk42cVbsWcUFhzED/fDDD3jnnXcQFxeHrKys+k7HIOPHj0dMTAxu3ryp17Z27VoEBgbihRdeqIfM2LOICw5jBiguLsaWLVvw5ptvIiwsDFFRUXoxv//+O/7xj3/AysoKzZo1w+DBgwE8OBx1/fp1vPfee5BIJJBIJACA+fPno3379qI+vvzyS3h5eQn3T506hf/5n/9Bs2bNoFQq0bNnT5w9e9bgvF999VU4OTnp5VtcXIzo6GiMHz8eubm5CA8PR/PmzWFtbY2AgABs2rSpxn6rO4ynUqlE49y4cQPDhg2DSqWCg4MDBg4ciGvXrgnthw4dQufOnWFjYwOVSoWuXbvi+vXrBs+NNT5ccBgzwNatW+Hn54c2bdpgxIgR+PHHH/HweW93796NwYMHo1+/fkhMTERsbCw6d+4MANi+fTtatGiBf//737h9+zZu375t8LhFRUUYPXo0jh49ihMnTsDX1xf9+vVDUVGRQY+3sLDAqFGjEBUVJco3OjoaVVVVCA8Px/3799GpUyfs3r0bKSkpmDhxIkaOHImTJ08anOffVVRUIDQ0FHZ2djhy5AiOHTsGW1tb9O3bF+Xl5aisrMSgQYPQs2dPJCcnIz4+HhMnThSKMWuiavXc04w1UV26dKEvv/ySiIgqKiqoWbNmdPDgQaE9ODiYIiIiHvl4T09P+uKLL0TbIiMjqV27dqJtX3zxBXl6ej6yn6qqKrKzs6Pff/9d2AaAduzY8cjHpKamEgBRvt27d6cRI0Y88jFhYWH0/vvvC/d79uxJ7777bo1jKpVK4ZT369evpzZt2pBWqxXay8rKSC6X0/79+yk3N5cA0KFDhx6ZA2t6eA+HscdIS0vDyZMnER4eDuDBXsPw4cPxww8/CDHnzp1D7969a33snJwcTJgwAb6+vlAqlVAoFCguLhYuO24IPz8/dOnSBT/++CMA4PLlyzhy5AjGjx8PAKiqqsLChQsREBAABwcH2NraYv/+/UaN8XdJSUm4fPky7OzsYGtrC1tbWzg4OOD+/fu4cuUKHBwcMGbMGISGhqJ///5YsWKFUXt+rHGyqO8EGGvofvjhB1RWVsLNzU3YRkSQyWT45ptvoFQqIZfLje7XzMxMdJgLgOhyxwAwevRo5ObmYsWKFfD09IRMJkNwcDDKy8uNGmv8+PF45513sHLlSqxduxYtW7ZEz549AQDLli3DihUr8OWXXyIgIAA2NjaYNm1ajWNIJJIacy8uLkanTp2wceNGvcc6OTkBeLBoYerUqdi3bx+2bNmCjz76CDExMXjxxReNmhtrPHgPh7EaVFZW4qeffsJnn32Gc+fOCbekpCS4ubkJX66/8MILeteMf5hUKkVVVZVom5OTE7Kzs0Uf3OfOnRPFHDt2DFOnTkW/fv3Qtm1byGQy3L171+h5DBs2DGZmZvj555/x008/Ydy4ccL3JceOHcPAgQMxYsQItGvXDj4+Prh06VKN/Tk5OYn2SNLT01FSUiLc79ixI9LT0+Hs7IxWrVqJbkqlUojr0KEDZs+ejePHj+P555/Hzz//bPTcWOPBBYexGuzatQv5+fkYP348nn/+edFt6NChwmG1yMhIbNq0CZGRkUhNTcX58+fx6aefCv14eXkhLi4Ot27dEgpGr1698Ndff2Hp0qW4cuUKVq5cib1794rG9/X1xfr165GamoqEhAREREQ80d6Ura0thg8fjtmzZ+P27dsYM2aMaIyYmBgcP34cqampmDRpEnJycmrs7+WXX8Y333yDxMREnD59GpMnT4alpaXQHhERgWbNmmHgwIE4cuQIMjIycOjQIUydOhU3b95ERkYGZs+ejfj4eFy/fh1//PEH0tPT8dxzzxk9N9aI1O9XSIw1bK+++ir169ev2raEhAQCQElJSUREtG3bNuGa8c2aNaMhQ4YIsfHx8fTCCy+QTCajh//svv32W3J3dycbGxsaNWoULVq0SLRo4OzZsxQYGEhWVlbk6+tL0dHRegsQ8JhFAzrHjx8nAHrzyc3NpYEDB5KtrS05OzvTRx99RKNGjaKBAwcKMX9fNHDr1i3q06cP2djYkK+vL+3Zs0e0aICI6Pbt2zRq1Chq1qwZyWQy8vHxoQkTJlBhYSFlZ2fToEGDyNXVlaRSKXl6etK8efOoqqrqsfNgjZeE6G8HYhljjLE6wIfUGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJcMFhjDFmElxwGGOMmQQXHMYYYybBBYcxxphJ/B+Qyu+xeLH2rQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining the model with adjusted parameters...\n",
            "\n",
            "\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
            "\n",
            "\u001b[91m Error during LLM call: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[00m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenAIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    609\u001b[0m                             )\n\u001b[0;32m--> 610\u001b[0;31m                         openai_client: OpenAI = self._get_openai_client(  # type: ignore\n\u001b[0m\u001b[1;32m    611\u001b[0m                             \u001b[0mis_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36m_get_openai_client\u001b[0;34m(self, is_async, api_key, api_base, api_version, timeout, max_retries, organization, client)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 _new_client = OpenAI(\n\u001b[0m\u001b[1;32m    365\u001b[0m                     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m                 )\n\u001b[0;32m-> 1626\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m                 response = openai_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1600\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0merror_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    718\u001b[0m                 \u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2f628b278061>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Execute the crew workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mml_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    768\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    300\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         result = agent.execute_task(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 {\n\u001b[1;32m    250\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_unknown_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             self._printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_context_length_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_context_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             )\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;34m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             answer = self.llm.call(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# --- 2) Make the completion call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                 response_message = cast(Choices, cast(ModelResponse, response).choices)[\n\u001b[1;32m    254\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   2982\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 ):\n\u001b[1;32m    355\u001b[0m                     \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     raise AuthenticationError(\n\u001b[0m\u001b[1;32m    357\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"AuthenticationError: {exception_provider} - {message}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                         \u001b[0mllm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-GW-ovk2fVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IhuyyvBY7DFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DhiBlGd7C6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2y40X14r7CyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Define a dummy LLM that does nothing\n",
        "class DummyLLM:\n",
        "    def __call__(self, prompt, **kwargs):\n",
        "        # Simply return an empty string or some default output\n",
        "        return \"\"\n",
        "    def complete(self, prompt, **kwargs):\n",
        "        return \"\"\n",
        "\n",
        "dummy_llm = DummyLLM()\n",
        "\n",
        "# Preprocessing agent\n",
        "def preprocess_data(df):\n",
        "    df = df.dropna()  # Handle missing values\n",
        "    X = df.iloc[:, :-1]  # Features\n",
        "    y = df.iloc[:, -1]   # Target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "preprocessor_agent = Agent(\n",
        "    role=\"Data Preprocessor\",\n",
        "    goal=\"Prepare data for ML training by handling missing values and splitting dataset.\",\n",
        "    backstory=\"An experienced data scientist specialized in data cleaning and preprocessing.\"\n",
        ")\n",
        "\n",
        "# Training agent\n",
        "def train_model(X_train, y_train):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "trainer_agent = Agent(\n",
        "    role=\"ML Trainer\",\n",
        "    goal=\"Train an ML model on the provided dataset.\",\n",
        "    backstory=\"A skilled ML engineer with expertise in model training and optimization.\"\n",
        ")\n",
        "\n",
        "# Evaluation agent\n",
        "def evaluate_model(model, X_test, y_test, train_error):\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.scatterplot(x=y_test, y=predictions, alpha=0.7)\n",
        "    plt.xlabel(\"Actual Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(\"Actual vs Predicted Values\")\n",
        "    plt.show()\n",
        "\n",
        "    retrain = mse > train_error * 1.2  # Retrain if test error is significantly higher\n",
        "    return mse, mae, r2, retrain\n",
        "\n",
        "evaluator_agent = Agent(\n",
        "    role=\"Model Evaluator\",\n",
        "    goal=\"Evaluate ML model performance and decide if retraining is needed.\",\n",
        "    backstory=\"A seasoned ML researcher with expertise in model evaluation.\"\n",
        ")\n",
        "\n",
        "# Retraining agent\n",
        "def retrain_model(retrain_flag):\n",
        "    if retrain_flag:\n",
        "        print(\"Retraining the model with adjusted parameters...\")\n",
        "        return False  # Placeholder for retraining logic\n",
        "    return retrain_flag\n",
        "\n",
        "retrainer_agent = Agent(\n",
        "    role=\"Model Retrainer\",\n",
        "    goal=\"Decide when to retrain the model for better accuracy.\",\n",
        "    backstory=\"A data scientist specialized in hyperparameter tuning and model optimization.\"\n",
        ")\n",
        "\n",
        "# Tasks\n",
        "data_preprocessing_task = Task(\n",
        "    description=\"Clean the dataset, remove missing values, and split into train-test sets.\",\n",
        "    agent=preprocessor_agent,\n",
        "    expected_output=\"Preprocessed data with training and test sets.\"\n",
        ")\n",
        "\n",
        "model_training_task = Task(\n",
        "    description=\"Train a Linear Regression model on the preprocessed data.\",\n",
        "    agent=trainer_agent,\n",
        "    expected_output=\"A trained Linear Regression model.\"\n",
        ")\n",
        "\n",
        "model_evaluation_task = Task(\n",
        "    description=\"Evaluate the trained model and determine if retraining is required.\",\n",
        "    agent=evaluator_agent,\n",
        "    expected_output=\"Evaluation metrics (MSE, MAE, R2 score) and retraining decision.\"\n",
        ")\n",
        "\n",
        "model_retraining_task = Task(\n",
        "    description=\"Retrain the model if necessary to improve accuracy.\",\n",
        "    agent=retrainer_agent,\n",
        "    expected_output=\"Retrained model or confirmation that no retraining was needed.\"\n",
        ")\n",
        "\n",
        "# Crew setup with the dummy LLM to avoid external LLM calls\n",
        "ml_crew = Crew(\n",
        "    agents=[preprocessor_agent, trainer_agent, evaluator_agent, retrainer_agent],\n",
        "    tasks=[data_preprocessing_task, model_training_task, model_evaluation_task, model_retraining_task],\n",
        "    llm=dummy_llm  # Pass the dummy LLM here\n",
        ")\n",
        "\n",
        "# Example dataset usage\n",
        "df = pd.read_csv(\"Salary_dataset.csv\")\n",
        "X_train, X_test, y_train, y_test = preprocess_data(df)\n",
        "model = train_model(X_train, y_train)\n",
        "train_error = mean_squared_error(y_train, model.predict(X_train))\n",
        "mse, mae, r2, retrain_flag = evaluate_model(model, X_test, y_test, train_error)\n",
        "retrain_model(retrain_flag)\n",
        "\n",
        "# Execute the crew workflow\n",
        "ml_crew.kickoff()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sSG1rLKH7Coi",
        "outputId": "a52ecb4b-422c-41c1-bc07-b68eccb432bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining the model with adjusted parameters...\n",
            "\n",
            "\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
            "\n",
            "\u001b[91m Error during LLM call: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[00m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenAIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    609\u001b[0m                             )\n\u001b[0;32m--> 610\u001b[0;31m                         openai_client: OpenAI = self._get_openai_client(  # type: ignore\n\u001b[0m\u001b[1;32m    611\u001b[0m                             \u001b[0mis_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36m_get_openai_client\u001b[0;34m(self, is_async, api_key, api_base, api_version, timeout, max_retries, organization, client)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 _new_client = OpenAI(\n\u001b[0m\u001b[1;32m    365\u001b[0m                     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m                 )\n\u001b[0;32m-> 1626\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m                 response = openai_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1600\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0merror_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    718\u001b[0m                 \u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-32fbba956336>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# Execute the crew workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mml_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    768\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    300\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         result = agent.execute_task(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 {\n\u001b[1;32m    250\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_unknown_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             self._printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_context_length_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_context_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             )\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;34m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             answer = self.llm.call(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# --- 2) Make the completion call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                 response_message = cast(Choices, cast(ModelResponse, response).choices)[\n\u001b[1;32m    254\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   2982\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 ):\n\u001b[1;32m    355\u001b[0m                     \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     raise AuthenticationError(\n\u001b[0m\u001b[1;32m    357\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"AuthenticationError: {exception_provider} - {message}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                         \u001b[0mllm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_spTRot7J7u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}